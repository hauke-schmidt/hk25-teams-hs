{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b09e42b4-975a-45de-9a5b-cfbd28869bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac_client import Client\n",
    "import eofetch\n",
    "import os\n",
    "import zipfile\n",
    "import track_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd0febb-28fa-46c7-a482-8dd2633445a0",
   "metadata": {},
   "source": [
    "#### Navigate the catalog and filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bd1e4d3-d923-40a8-a50d-fd8b2c9ad47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_url = 'https://eocat.esa.int/eo-catalogue'\n",
    "catalog = Client.open(catalog_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "479e62a9-94f6-40d6-abe1-d9a45261a4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out https://earthcarehandbook.earth.esa.int/catalogue/index for product descriptions\n",
    "# prod_type='CPR_CLD_2A' #Cloud profiling radar\n",
    "prod_type='ATL_ICE_2A'\n",
    "\n",
    "search = catalog.search(\n",
    "    #collections = ['EarthCAREL1Validated'], # uncommment for searching L1 data\n",
    "    collections = ['EarthCAREL2Validated'], # uncomment for searching L2 data \n",
    "    filter = f\"productType='{prod_type}'\", # Filter by product type, there are more options for filtering here too! \n",
    "    datetime = ['2025-04-01T00:00:00.000Z', '2025-04-30T00:00:00.000Z'], # filter by temporal extent \n",
    "    method = 'GET',\n",
    "    bbox = [8, 76, 33, 81], #or [9, 43, 23, 47], # bounding box is defined by the bottom left corner (longmin latmin) and the top right corner coordinates (longmax latmax) \n",
    "\n",
    "    max_items=100  # Adjust as needed, if you don't add max_items over 100000s of products though this could take really long \n",
    ")\n",
    "\n",
    "items = list(search.items())\n",
    "\n",
    "id_lst = []\n",
    "h_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42c97c55-4621-427f-bc44-9414bb18feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in items:\n",
    "    if prod_type in item.id: id_lst.append(item.assets[\"enclosure\"].href) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a10424-d7bc-44f3-a3c2-05bae0141b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to set your username and password for Earth login / OADS\n",
    "os.environ[\"OADS_USERNAME\"] = \"******\"\n",
    "os.environ[\"OADS_PASSWORD\"] = \"#*****\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "460b3b03-427a-431e-9b48-d065badb9c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data as .zip files\n",
    "eofetch.download(id_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc3439b",
   "metadata": {},
   "source": [
    "The following will unzip the downloaded files and place them into a directory strucuture which should be easy to use.\n",
    "A `track_datetime` object is created and saves the dates and times of tracks of the region of interest. This can be saved to be reloaded into your own analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed572e-53e2-400a-9802-f513d3eb8b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc='svalbard' #setting this so that we can name an object\n",
    "               #which contains the dates / times of passes over a region. \n",
    "               \n",
    "#################################################\n",
    "### Uncomment below to read in pickled object ###\n",
    "#################################################\n",
    "\n",
    "pklpath=f'/work/bb1086/b383354/earth-care-data/track_datetimes/{loc}_tracks_times.pkl'\n",
    "if os.path.isfile(pklpath):\n",
    "    dates_obj=track_datetime.read_from_pickle(pklpath) \n",
    "else:\n",
    "    dates_obj=track_datetime.track_dates()\n",
    "\n",
    "\n",
    "for file in id_lst:\n",
    "    fi=file.rsplit('/',1)[1]\n",
    "    a=fi.rsplit('_',3)[1]\n",
    "    yy=a[0:4]\n",
    "    mm=a[4:6]\n",
    "    dd=a[6:8]\n",
    "    hr=a[9:11]\n",
    "    mn=a[11:13]\n",
    "\n",
    "    \n",
    "    path=f'/work/bb1086/b383354/earth-care-data/{yy}/{mm}/{dd}'  #This is my path on work, you can set to your own\n",
    "                                        \n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "        try:\n",
    "            with zipfile.ZipFile(fi, 'r') as zip_ref:\n",
    "                zip_ref.extract(f\"{fi.rsplit('.',1)[0]}.h5\", path=path) #extract the files work directory structure\n",
    "                dates_obj.add_time(date=f'{yy}-{mm}-{dd}',time=f'T{hr}:{mn}:00')\n",
    "                \n",
    "        except:\n",
    "            print(f'could not unzip file {fi}')\n",
    "            \n",
    "    os.remove(f'./{fi}') #remove the downloaded file\n",
    "\n",
    "\n",
    "## maybe should save pickles with instrument name too?\n",
    "\n",
    "if not os.path.isdir(f'{path}/../../../track_datetimes'):\n",
    "    os.makedirs(f'{path}/../../../track_datetimes', exist_ok=True)\n",
    "dates_obj.save_pickle(f'{path}/../../../track_datetimes/{loc}_track_datetimes.pkl')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
